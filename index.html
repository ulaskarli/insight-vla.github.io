<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>INSIGHT: Inference-time Sequence Introspection for VLAs</title>
  <meta name="description" content="INSIGHT: token-level uncertainty for timely human help in Vision-Language-Action rollouts.">
  <meta property="og:title" content="INSIGHT — Help-Triggering in VLAs">
  <meta property="og:description" content="Token-level uncertainty → timely human help for safer, more reliable VLA rollouts.">
  <meta property="og:type" content="website">
  <meta property="og:image" content="static/images/teaser.jpg">
  <link rel="icon" href="static/images/favicon.ico">

  <!-- Fonts and CSS -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <!-- Scripts -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
  <!-- Hero Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">INSIGHT:<br><span style="font-size:2.4rem;">Inference-time Sequence Introspection for Help-Triggering in VLAs</span></h1>
            <h2 class="subtitle is-4">ICRA 2026 Submission</h2>

            <!-- Authors -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">Ulas Berk Karli<sup>1</sup>,</span>
              <span class="author-block">Co-authors TBD<sup>1</sup></span>
              <br>
              <span class="author-block"><sup>1</sup>Yale University</span>
            </div>

            <!-- Links -->
            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="static/paper.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/ulaskarli/insight-vla-help-triggers" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser Video -->
  <section class="hero teaser teaser-video">
    <div class="container is-max-desktop has-text-centered">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline width="80%">
          <source src="static/videos/teaser.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </section>

  <!-- Abstract Section -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Abstract</h2>
      <p class="content has-text-justified">
        Recent Vision-Language-Action (VLA) models show strong generalization capabilities, yet they lack introspective mechanisms for anticipating failures and requesting help from a human supervisor. We present <b>INSIGHT</b>, a learning framework for leveraging token-level uncertainty signals to predict when a VLA should request help. Using π₀-FAST as the underlying model, we extract per-token <i>entropy</i>, <i>log-probability</i>, and Dirichlet-based estimates of <i>aleatoric and epistemic uncertainty</i>, and train compact transformer classifiers to map these sequences to help triggers. We explore supervision regimes for strong or weak supervision, and extensively compare them across in-distribution and out-of-distribution tasks. Our results show a trade-off: strong labels enable models to capture fine-grained uncertainty dynamics for reliable help detection, while weak labels, though noisier, still support competitive introspection when training and evaluation are aligned, offering a scalable path when dense annotation is impractical. Crucially, we find that modeling the temporal evolution of token-level uncertainty signals with transformers provides far greater predictive power than static sequence-level scores. This study provides the first systematic evaluation of uncertainty-based introspection in VLAs, opening future avenues for active learning and for real-time error mitigation through selective human intervention.
      </p>
    </div>
  </section>

  <!-- Results Section (placeholder for boxplots and tables) -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results</h2>

      <h3 class="title is-4">In-Distribution Performance</h3>
      <figure>
        <img src="static/images/ID_sign.jpeg" alt="Boxplots of accuracy, F1 across 10 folds.">
        <figcaption>Results for the transformer (INSIGHT) and Conformal Prediction based on entropy (CP-E) and perplexity (CP-P). Each box plot indicates mean (dashed horizontal lines) and median (solid horizontal lines) performance across folds. Error bars indicate 1 standard deviation. Significance by paired Wilcoxon (two-sided) across folds: * p&lt;0.05, ** p&lt;0.01.</figcaption>
      </figure>

      <h3 class="title is-4">Distribution Shift Performance</h3>
      <figure>
        <img src="static/images/OOD.jpeg" alt="Boxplots under distribution shift.">
        <figcaption>Performance under distribution shift. Strong supervision captures fine-grained uncertainty; Weak supervision competitive when train/eval align.</figcaption>
      </figure>

      <h3 class="title is-4">Large In-Distribution Performance</h3>
      <figure>
        <img src="static/images/LID.jpeg" alt="Large-scale in-distribution results.">
        <figcaption>Temporal modeling of token sequences vs static sequence-level scores.</figcaption>
      </figure>

      <h3 class="title is-4">Simulation OOD</h3>
      <figure>
        <img src="static/images/Sim OOD.jpeg" alt="Simulation OOD results.">
        <figcaption>Performance under simulated OOD setup.</figcaption>
      </figure>

      <h3 class="title is-4">Help Timing & Frequency</h3>
      <div class="table-card">
        <table class="table is-bordered is-striped is-hoverable is-fullwidth">
          <thead>
            <tr>
              <th>Method</th>
              <th>TTFH (fail) ↓</th>
              <th>Triggers<sub>succ</sub> ↓</th>
              <th>Triggers<sub>fail</sub> (≥ 1 ok)</th>
              <th>Trigger Rate (success) ↓</th>
              <th>Trigger Rate (fail) ↑</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>CP-W (Entropy)</td>
              <td>6.891 ± 2.257</td>
              <td>0.457 ± 0.302</td>
              <td>1.721 ± 0.739</td>
              <td>0.031 ± 0.020</td>
              <td>0.118 ± 0.050</td>
            </tr>
            <tr>
              <td><b>Strong Superv.</b></td>
              <td><b>5.597 ± 0.809</b></td>
              <td>0.710 ± 0.440</td>
              <td><b>7.062 ± 1.225</b></td>
              <td>0.047 ± 0.029</td>
              <td><b>0.472 ± 0.081</b></td>
            </tr>
            <tr>
              <td>Weak Superv.</td>
              <td>7.929 ± 1.867</td>
              <td><b>0.122 ± 0.172</b></td>
              <td>1.566 ± 1.025</td>
              <td><b>0.008 ± 0.011</b></td>
              <td>0.105 ± 0.069</td>
            </tr>
          </tbody>
        </table>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>Website borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> and <a href="https://openvla.github.io/">OpenVLA</a> under <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.</p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Rollouts Section with dropdown filters -->
  <section id="rollouts" class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Rollouts</h2>
      <div class="field is-grouped is-grouped-multiline" style="margin-bottom:14px">
        <div class="control">
          <div class="select is-link is-small">
            <select id="datasetSel" aria-label="Dataset filter">
              <option value="">All Datasets</option>
              <option value="ID">ID</option>
              <option value="Shift">Shift</option>
              <option value="Sim-OOD">Sim-OOD</option>
            </select>
          </div>
        </div>
        <div class="control">
          <div class="select is-link is-small">
            <select id="outcomeSel" aria-label="Outcome filter">
              <option value="">All Outcomes</option>
              <option value="Success">Success</option>
              <option value="Fail">Fail</option>
            </select>
          </div>
        </div>
      </div>

      <!-- Grid -->
      <div id="rolloutGrid" class="columns is-multiline is-variable is-4"></div>

      <p class="has-text-grey is-size-6" id="rolloutEmpty" style="display:none;margin-top:12px">
        No rollouts match the selected filters.
      </p>
    </div>
  </section>

  <script>
    // ===== Rollout data (replace with your real files) =====
    const ROLLOUTS = [
      // {src:"static/videos/lift_ID_success_STRONG_ep42_ttfh3.mp4", thumb:"static/images/lift_ID_ep42.jpg", dataset:"ID", outcome:"Success", caption:"Lift • ID • Success"},
      // {src:"static/videos/place_Shift_fail_WEAK_ep07_ttfh2.mp4", thumb:"static/images/place_Shift_ep07.jpg", dataset:"Shift", outcome:"Fail", caption:"Place • Shift • Fail"},
    ];

    // ===== Render & Filter =====
    const grid = document.getElementById('rolloutGrid');
    const emptyMsg = document.getElementById('rolloutEmpty');
    const datasetSel = document.getElementById('datasetSel');
    const outcomeSel = document.getElementById('outcomeSel');

    function renderRollouts(){
      const ds = datasetSel.value;
      const oc = outcomeSel.value;
      const items = ROLLOUTS.filter(r => (!ds || r.dataset===ds) && (!oc || r.outcome===oc));

      grid.innerHTML = items.map(r => `
        <div class="column is-6">
          <figure class="image">
            <video src="${r.src}" poster="${r.thumb||''}" controls playsinline preload="metadata" style="border-radius:12px;width:100%"></video>
            <figcaption class="has-text-grey" style="margin-top:6px">${r.caption||`${r.dataset} • ${r.outcome}`}</figcaption>
          </figure>
        </div>
      `).join('');

      emptyMsg.style.display = items.length ? 'none' : 'block';
    }

    if (datasetSel && outcomeSel && grid){
      datasetSel.addEventListener('change', renderRollouts);
      outcomeSel.addEventListener('change', renderRollouts);
      renderRollouts();
    }
  </script>

</body>
</html>
