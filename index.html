<!--
INSIGHT: Inference-time Sequence Introspection for Help-Triggering in VLAs
Website scaffold built on top of nerfies/nerfies.github.io structure.
This single file is a drop-in replacement for your root index.html.
If your repo already has extra CSS/JS, keep them; this file uses minimal inline CSS + one small JS (rollouts.js) you’ll add under /js/.

Folders assumed by this page:
  /static/images/    (teaser.jpg/png, method.svg, thumbs)
  /static/videos/    (short .mp4/.webm rollouts)
  /static/paper/     (insight_icra26.pdf)
  /static/downloads/ (checkpoints, feature dumps, reproduce_figs.zip)
  /js/rollouts.js    (rollout metadata + filter rendering)
  /static/bibtex.bib (BibTeX entry)

Replace TODO: ... markers with your content.
-->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>INSIGHT — Inference-time Sequence Introspection for Help-Triggering in VLAs</title>
  <meta name="description" content="INSIGHT: token-level uncertainty for timely human help in Vision-Language-Action rollouts."/>
  <meta property="og:title" content="INSIGHT — Help-Triggering in VLAs"/>
  <meta property="og:description" content="Token-level uncertainty → timely human help for safer, more reliable VLA rollouts."/>
  <meta property="og:type" content="website"/>
  <meta property="og:image" content="static/images/teaser.jpg"/>
  <link rel="icon" href="static/images/favicon.ico"/>
  <style>
    :root{
      --bg:#ffffff; --panel:#f8f9fa; --ink:#1a1a1a; --muted:#555; --accent:#007acc; --accent2:#2ca02c;
      --maxw:1100px; --gap:22px; --radius:12px; --shadow:0 4px 12px rgba(0,0,0,.1);
    }
    html,body{background:var(--bg);color:var(--ink);font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial, "Noto Sans";}
    a{color:var(--accent)} a:hover{opacity:.85}
    .wrap{max-width:var(--maxw);margin:0 auto;padding:36px 20px}
    header.hero{display:grid;grid-template-columns:1.1fr .9fr;gap:var(--gap);align-items:center}
    .panel{background:var(--panel);border-radius:var(--radius);box-shadow:var(--shadow)}
    .hero-copy{padding:28px}
    h1{font-size:clamp(28px,4vw,44px);margin:.2em 0 .3em}
    .subtitle{color:var(--muted);font-size:1.05rem;line-height:1.5}
    .badges{display:flex;flex-wrap:wrap;gap:10px;margin-top:18px}
    .btn{display:inline-block;padding:10px 14px;border-radius:8px;background:#e9ecef;border:1px solid #cfd4da;color:var(--ink);text-decoration:none}
    .btn strong{color:var(--accent)}
    .teaser{overflow:hidden;border-radius:var(--radius)}
    .teaser video,.teaser img{width:100%;height:auto;display:block}
    nav{position:sticky;top:0;background:#ffffffee;backdrop-filter:saturate(140%) blur(6px);z-index:20;border-bottom:1px solid #ddd}
    nav .navwrap{max-width:var(--maxw);margin:0 auto;display:flex;gap:18px;align-items:center;padding:10px 20px}
    nav a{color:var(--ink);text-decoration:none;padding:6px 10px;border-radius:6px}
    nav a:hover{background:#f1f3f5}
    section{margin-top:42px}
    section .card{padding:26px}
    h2{font-size:clamp(22px,3vw,32px);margin:.1em 0 .6em}
    .twocol{display:grid;grid-template-columns:1fr 1fr;gap:var(--gap)}
    .metrics{display:grid;grid-template-columns:repeat(3,1fr);gap:var(--gap)}
    .metric{padding:18px;border:1px solid #ddd;border-radius:10px;background:#fff}
    .metric .v{font-weight:700;font-size:22px;color:var(--accent)}
    figure{margin:0}
    figcaption{color:var(--muted);font-size:.95rem;margin-top:8px}
    #filters{display:flex;flex-wrap:wrap;gap:10px;margin-bottom:14px}
    #filters select{background:#fff;color:var(--ink);border:1px solid #ccc;border-radius:6px;padding:6px}
    #rollout-grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(260px,1fr));gap:14px}
    .tile{border:1px solid #ddd;border-radius:10px;overflow:hidden;background:#fff}
    .tile video{display:block;width:100%;height:auto}
    .tile figcaption{padding:10px}
    .foot{color:var(--muted);font-size:.9rem;margin-top:40px}
    .table-card{background:#fff;border:1px solid #ddd;border-radius:10px;box-shadow:var(--shadow);overflow:auto}
    .table-card table{width:100%;border-collapse:collapse;min-width:720px}
    .table-card th,.table-card td{padding:10px 12px;text-align:center;border-bottom:1px solid #eee;white-space:nowrap}
    .table-card th:first-child,.table-card td:first-child{text-align:left}
    .table-card thead th{font-weight:700;background:#f3f5f7;color:#333}
    .table-card tbody tr:hover{background:#fafbfc}
    .kpi-up{color:#156f00;font-weight:700}     /* ↑ higher is better */
    .kpi-down{color:#0054a6;font-weight:700}   /* ↓ lower is better */
    .caption{color:var(--muted);font-size:.95rem;margin-top:8px}
    @media (max-width:980px){header.hero{grid-template-columns:1fr}}
  </style>
</head>
<body>
  <nav>
    <div class="navwrap">
      <a href="#top"><strong>INSIGHT</strong></a>
      <a href="#abstract">Abstract</a>
      <a href="#method">Method</a>
      <a href="#results">Results</a>
      <a href="#rollouts">Rollouts</a>
      <a href="#models">Models</a>
      <a href="#data">Data</a>
      <a href="#bibtex">BibTeX</a>
      <a href="#team">Team</a>
    </div>
  </nav>

  <main id="top" class="wrap">
    <header class="hero">
      <div class="panel teaser">
        <!-- Prefer a short, silent teaser video; include an IMG fallback for first paint -->
        <video src="static/videos/teaser.mp4" poster="static/images/teaser.jpg" autoplay muted loop playsinline></video>
      </div>
      <div class="panel hero-copy">
        <h1>INSIGHT: Inference-time Sequence Introspection for Help-Triggering in VLAs</h1>
        <p class="subtitle">Token-level uncertainty → timely human help for safer, more reliable Vision–Language–Action rollouts. <!--br/>ICRA 2026 Submission.--> </p>
        <p class="subtitle" style="margin-top:8px">Authors: <span>Ulas Berk Karli, Ziyao Shangguan, and Tesca Fitzgerald</span></p>
        <div class="badges">
          <a class="btn" href="https://github.com/ulaskarli/insight-vla-help-triggers"><strong>Code</strong></a>
          <!-- a class="btn" href="#models">Models</a -->
          <!-- a class="btn" href="#data">Data</a -->
          <a class="btn" href="#bibtex">BibTeX</a>
          <a class="btn" href="https://arxiv.org/abs/TO-BE-ADDED">arXiv</a>
          <a class="btn" href="mailto:ulasberk.karli@yale.edu">Contact</a>
        </div>
      </div>
    </header>

    <!-- Abstract -->
    <section id="abstract" class="panel card">
      <h2>Abstract</h2>
      <p>Recent Vision–Language–Action (VLA) models exhibit strong generalization but lack mechanisms to anticipate failures and request timely human help. <strong>INSIGHT</strong> introduces a learning framework that leverages token‑level uncertainty signals to predict when intervention is needed. Built on top of π₀‑FAST, our approach extracts entropy, log‑probability, and Dirichlet‑based estimates of aleatoric and epistemic uncertainty, then trains compact transformer classifiers to map these sequences to help triggers. We study both strong and weak supervision regimes, comparing their effectiveness across in‑distribution and out‑of‑distribution tasks. Strong labels capture fine‑grained uncertainty dynamics for reliable detection, while weak labels, though noisier, remain competitive when training and evaluation align—offering scalability where dense annotation is impractical. Crucially, modeling temporal evolution of token‑level uncertainty yields far greater predictive power than static sequence‑level scores. This work provides the first systematic evaluation of uncertainty‑based introspection in VLAs, paving the way for active learning and real‑time error mitigation through selective human intervention.</p>
    </section>

    <!-- Method -->
    <section id="method" class="panel card">
      <h2>Method</h2>
      <div class="twocol">
        <figure>
          <img src="static/images/icra_teaser.svg" alt="Method diagram: token distributions → uncertainty features → transformer → help/no-help"/>
          <figcaption>INSIGHT consumes token distributions from a VLA (e.g., π₀‑FAST), computes uncertainty features, and predicts help triggers online.</figcaption>
        </figure>
        <div>
          <ul>
            <li><strong>Inputs:</strong> per-token distributions → features: entropy, −log p, aleatoric (AU) and epistemic (EU) uncertainty.</li>
            <li><strong>Decision module:</strong> compact transformer over short windows, outputs <em>help/no-help</em> at step <em>t</em>.</li>
            <li><strong>Training regimes:</strong> <em>Strong</em> (step labels) and <em>Weak</em> (episode labels, MIL-style) + CP baselines for comparison.</li>
            <li><strong>Deployment:</strong> triggers enable teleop takeover or preference queries; success episodes see fewer interrupts, fails get early warnings.</li>
          </ul>
        </div>
      </div>
    </section>

    <!-- Results at a glance -->
    <section id="results" class="panel card">
      <h2>Results</h2>

      <!-- Quick sub-nav -->
      <div class="results-nav" style="display:flex;flex-wrap:wrap;gap:8px;margin:-6px 0 18px 0">
        <a class="btn" href="#res-overview">Overview</a>
        <a class="btn" href="#res-id">In-Distribution</a>
        <a class="btn" href="#res-ds">Distribution-Shift</a>
        <a class="btn" href="#res-lid">Large In-Distribution</a>
        <a class="btn" href="#res-ood">Sim-OOD</a>
        <a class="btn" href="#res-timing">Help Timing</a>
      </div>

      <!-- 0) Overview (headline numbers) -->
      <section id="res-overview" style="margin-top:6px">
        <h3 style="margin:.4em 0 .6em;font-size:1.2rem;color:#333">Overview</h3>
        <div class="metrics">
          <div class="metric"><div class="v" id="m_id">TODO</div><div>In-Distribution F1 (Strong)</div></div>
          <div class="metric"><div class="v" id="m_shift">TODO</div><div>Shifted Eval F1 (Strong→Weak)</div></div>
          <div class="metric"><div class="v" id="m_ttfh">TODO</div><div>TTFH ↓ (Fail Episodes)</div></div>
        </div>
      </section>

      <!-- 1) In-Distribution (boxplot) -->
      <section id="res-id" style="margin-top:30px">
        <h3 style="margin:.4em 0 .6em;font-size:1.2rem;color:#333">In-Distribution Performance</h3>
        <figure>
          <img src="static/images/ID_sign.jpeg" alt="In-distribution boxplots comparing INSIGHT to CP baselines across folds.">
          <figcaption>
            Results for the transformer (INSIGHT) and Conformal Prediction based on entropy (CP-E) and perplexity (CP-P).
            Each box plot indicates mean (dashed horizontal lines) and median (solid horizontal lines) performance across folds.
            Error bars indicate 1 standard deviation.
            Significance by paired Wilcoxon (two-sided) across folds: * p&lt;0.05, ** p&lt;0.01.
          </figcaption>
        </figure>
      </section>

      <!-- 2) Distribution Shift (boxplot) -->
      <section id="res-ds" style="margin-top:30px">
        <h3 style="margin:.4em 0 .6em;font-size:1.2rem;color:#333">Distribution-Shift Performance</h3>
        <figure>
          <img src="static/images/OOD.jpeg" alt="Distribution-shift boxplots comparing methods across folds.">
          <figcaption>
            Results for the transformer (INSIGHT) and Conformal Prediction based on entropy (CP-E) and perplexity (CP-P).
            Each box plot indicates mean (dashed horizontal lines) and median (solid horizontal lines) performance across folds.
            Error bars indicate 1 standard deviation.
            Significance by paired Wilcoxon (two-sided) across folds: * p&lt;0.05, ** p&lt;0.01.
          </figcaption>
        </figure>
      </section>

      <!-- 3) Large In-Distribution (boxplot) -->
      <section id="res-lid" style="margin-top:30px">
        <h3 style="margin:.4em 0 .6em;font-size:1.2rem;color:#333">Large In-Distribution Performance</h3>
        <figure>
          <img src="static/images/LID.jpeg" alt="Large in-distribution boxplots comparing methods across folds.">
          <figcaption>
            Results for the transformer (INSIGHT) and Conformal Prediction based on entropy (CP-E) and perplexity (CP-P).
            Each box plot indicates mean (dashed horizontal lines) and median (solid horizontal lines) performance across folds.
            Error bars indicate 1 standard deviation.
            Significance by paired Wilcoxon (two-sided) across folds: * p&lt;0.05, ** p&lt;0.01.
          </figcaption>
        </figure>
      </section>

      <!-- 4) Simulation OOD (bar/plot) -->
      <section id="res-ood" style="margin-top:30px">
        <h3 style="margin:.4em 0 .6em;font-size:1.2rem;color:#333">Simulation-OOD</h3>
        <figure>
          <img src="static/images/Sim_OOD.jpeg" alt="Simulation OOD performance summary.">
          <figcaption>Performance under simulated OOD setup.</figcaption>
        </figure>
      </section>

      <!-- 4) Timing -->
      <section id="res-timing" style="margin-top:30px">
      <h3 style="margin:.4em 0 .6em;font-size:1.2rem;color:#333">Help Timing & Frequency</h3>

      <div class="table-card">
        <table class="table-metrics">
          <thead>
            <tr>
              <th>Method</th>
              <th>TTFH (fail) <span class="kpi-down">↓</span></th>
              <th>Triggers<sub>succ</sub> <span class="kpi-down">↓</span></th>
              <th>Triggers<sub>fail</sub> (≥ 1 ok)</th>
              <th>Trigger Rate (success) <span class="kpi-down">↓</span></th>
              <th>Trigger Rate (fail) <span class="kpi-up">↑</span></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>CP-W (Entropy)</td>
              <td>6.891 &plusmn; 2.257</td>
              <td>0.457 &plusmn; 0.302</td>
              <td>1.721 &plusmn; 0.739</td>
              <td>0.031 &plusmn; 0.020</td>
              <td>0.118 &plusmn; 0.050</td>
            </tr>
            <tr>
              <td><strong>Strong Superv.</strong></td>
              <td><strong>5.597 &plusmn; 0.809</strong></td>
              <td>0.710 &plusmn; 0.440</td>
              <td><strong>7.062 &plusmn; 1.225</strong></td>
              <td>0.047 &plusmn; 0.029</td>
              <td><strong>0.472 &plusmn; 0.081</strong></td>
            </tr>
            <tr>
              <td>Weak Superv.</td>
              <td>7.929 &plusmn; 1.867</td>
              <td><strong>0.122 &plusmn; 0.172</strong></td>
              <td>1.566 &plusmn; 1.025</td>
              <td><strong>0.008 &plusmn; 0.011</strong></td>
              <td>0.105 &plusmn; 0.069</td>
            </tr>
          </tbody>
        </table>
      </div>

      <p class="caption">
        Time-to-first-help (TTFH; lower is better) and trigger statistics by method.
        As desired, success episodes show lower trigger rates, while failing episodes trigger more frequently and earlier.
      </p>
    </section>

    <!-- Rollout gallery -->
    <section id="rollouts" class="panel card">
      <h2>Rollout Gallery</h2>
      <div id="filters">
        <select data-filter="task"><option value="">All Tasks</option><option>Lift</option><option>Place</option><option>Push</option></select>
        <select data-filter="setting"><option value="">All Settings</option><option>ID</option><option>Shift</option><option>Sim‑OOD</option></select>
        <select data-filter="outcome"><option value="">All Outcomes</option><option>Success</option><option>Fail</option></select>
        <select data-filter="model"><option value="">All Models</option><option>Strong</option><option>Weak</option><option>CP‑E</option><option>CP‑P</option></select>
      </div>
      <div id="rollout-grid"></div>
      <script src="js/rollouts.js"></script>
    </section>

    <!-- Model Zoo -->
    <section id="models" class="panel card">
      <h2>Models</h2>
      <ul>
        <li><strong>INSIGHT‑Strong</strong>: step‑label trained; <a href="static/downloads/insight_strong.ckpt">checkpoint</a> • <a href="#">card</a></li>
        <li><strong>INSIGHT‑Weak</strong>: episode‑label trained (MIL); <a href="static/downloads/insight_weak.ckpt">checkpoint</a> • <a href="#">card</a></li>
        <li><strong>INSIGHT‑Jumbo</strong>: multi‑dataset; <a href="static/downloads/insight_jumbo.ckpt">checkpoint</a> • <a href="#">card</a></li>
        <li><strong>Baselines</strong>: CP‑Entropy, CP‑Perplexity configs; <a href="static/downloads/cp_configs.zip">configs</a></li>
      </ul>
    </section>

    <!-- Data & Reproducibility -->
    <section id="data" class="panel card">
      <h2>Data & Reproducibility</h2>
      <p>We release a small feature dump (token‑level uncertainty sequences) and scripts to reproduce key figures.</p>
      <ul>
        <li><a href="static/downloads/example_features.zip">example_features.zip</a> (small subset)</li>
        <li><a href="static/downloads/reproduce_figs.zip">reproduce_figs.zip</a> (plot scripts & CSVs)</li>
        <li><a href="https://github.com/your-org/insight-vla-help-triggers">Code repository</a></li>
      </ul>
    </section>

    <!-- BibTeX -->
    <section id="bibtex" class="panel card">
      <h2>BibTeX</h2>
      <pre style="white-space:pre-wrap;background:#0f1421;border:1px solid #1b2435;border-radius:12px;padding:16px;overflow:auto">
@inproceedings{TODO2026insight,
  title={INSIGHT: Inference-time Sequence Introspection for Help-Triggering in Vision-Language-Action Models},
  author={TODO},
  booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
  year={2026}
}
      </pre>
      <p><a href="static/bibtex.bib">Download .bib</a></p>
    </section>

    <!-- Team -->
    <section id="team" class="panel card">
      <h2>Team</h2>
      <p>TODO: Author list with affiliations and links.</p>
    </section>

    <p class="foot">© 2025 INSIGHT authors. Site based on the Nerfies template. Media under the respective licenses.</p>
  </main>

  <!-- Minimal analytics (optional) -->
  <!-- <script defer data-domain="insight-vla.github.io" src="https://plausible.io/js/script.js"></script> -->
</body>
</html>

<!-- ======= Create /js/rollouts.js with the following starter =======
// /js/rollouts.js
const data = [
  {src:"static/videos/lift_ID_success_STRONG_ep42_ttfh3.mp4", thumb:"static/images/lift_ID_ep42.jpg", task:"Lift", setting:"ID", outcome:"Success", model:"Strong", ttFH:3, notes:"Early help stabilized grasp."},
  {src:"static/videos/place_Shift_fail_WEAK_ep07_ttfh2.mp4", thumb:"static/images/place_Shift_ep07.jpg", task:"Place", setting:"Shift", outcome:"Fail", model:"Weak", ttFH:2, notes:"Late trigger; contact slip."}
];

const grid = document.getElementById('rollout-grid');
function render(){
  const sels=[...document.querySelectorAll('#filters [data-filter]')];
  const filtered = data.filter(d=>sels.every(sel=>{const k=sel.dataset.filter;return !sel.value || d[k]===sel.value;}));
  grid.innerHTML = filtered.map(d=>`
    <figure class="tile" data-task="${d.task}" data-setting="${d.setting}" data-outcome="${d.outcome}" data-model="${d.model}">
      <video src="${d.src}" poster="${d.thumb}" muted loop playsinline></video>
      <figcaption>${d.task} • ${d.setting} • ${d.model} • TTFH=${d.ttFH}<br/>${d.notes}</figcaption>
    </figure>`).join('');
}

document.getElementById('filters').addEventListener('change', render);
render();

======= End rollouts.js starter ======= -->